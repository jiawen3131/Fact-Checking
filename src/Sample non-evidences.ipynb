{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ed5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "from pandas.io.json import json_normalize\n",
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "\n",
    "\n",
    "\n",
    "##function to find wikipage with the revision and query negative examples\n",
    "#function to query claims for real revisions (with revision_id) and synthetic revisions(with no revision id)\n",
    "def query_claims(revision_id, page, gold_evidence, revision_type):\n",
    "    negative_evidences = []\n",
    "    if revision_type == 'real':\n",
    "        url = \"https://en.wikipedia.org/w/index.php?title=\" + str(page) + \"&oldid=\" + str(revision_id)\n",
    "    else:\n",
    "        url = \"https://en.wikipedia.org/wiki/\"+ str(page)\n",
    "    try:\n",
    "        page = requests.get(url)\n",
    "    except:\n",
    "        list_none = [None] * 10\n",
    "        return list_none\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    object = soup.find(id=\"mw-content-text\")\n",
    "    items = object.find_all('p')\n",
    "    for i in range(len(items)):\n",
    "        extracted_para = items[i].get_text()\n",
    "        extracted_sentences = nltk.tokenize.sent_tokenize(extracted_para)\n",
    "        if len(extracted_sentences) > 0:\n",
    "            for j in range(len(extracted_sentences)):\n",
    "                neg_evidence = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", extracted_sentences[j])\n",
    "                if not check_evidence(neg_evidence,gold_evidence) and len(neg_evidence) >= 5:\n",
    "                    negative_evidences.append(neg_evidence)\n",
    "                    if (len(negative_evidences)==9):\n",
    "                        return negative_evidences\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "    return [None]*10\n",
    "            \n",
    "\n",
    "#function to check that negative example is not the actual evidence\n",
    "def check_evidence(neg_example, gold_evidence):\n",
    "    neg_example=re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", neg_example)\n",
    "    gold_evidence=re.sub(\"[\\(\\[].*?[\\)\\]]\", \" \", gold_evidence)\n",
    "    neg_example=re.sub(r'[^\\w]', ' ', neg_example)\n",
    "    gold_evidence=re.sub(r'[^\\w]', ' ', gold_evidence)\n",
    "    neg_example = neg_example.replace(\" \",\"\").lower()\n",
    "    gold_evidence = gold_evidence.replace(\" \",\"\").lower()\n",
    "    if neg_example == gold_evidence:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "#function to add negative examples to original evidence and format evidences into dataframe that can be used for training\n",
    "def format_examples(df):\n",
    "    final_df = df[['unique_id','claim', 'evidence','label']].copy()\n",
    "    final_df = final_df.rename(columns={'unique_id':'id'})\n",
    "    neg_examples_list_dict = []\n",
    "    \n",
    "    for row in tqdm(range(len(df))):\n",
    "        neg_eg = query_claims(df.iloc[row]['wiki_revision_id'],df.iloc[row]['page'],\n",
    "                          df.iloc[row]['evidence'], df.iloc[row]['revision_type'])\n",
    "        #print(neg_eg)\n",
    "        if neg_eg[0] != None:\n",
    "            for neg in neg_eg:\n",
    "                neg_examples_dict = {}\n",
    "                neg_examples_dict['id'] = df.iloc[row]['unique_id']\n",
    "                neg_examples_dict['claim'] = df.iloc[row]['claim']\n",
    "                neg_examples_dict['evidence'] = neg\n",
    "                neg_examples_dict['label'] = 0\n",
    "                neg_examples_list_dict.append(neg_examples_dict)\n",
    "        \n",
    "        else:\n",
    "            final_df = final_df[final_df.id != df.iloc[row]['unique_id']]\n",
    "        \n",
    "        \n",
    "        \n",
    "    neg_df = pd.DataFrame(neg_examples_list_dict) \n",
    "    frames = [final_df, neg_df]\n",
    "    result = pd.concat(frames)\n",
    "    result_sort = result.sort_values('id') \n",
    "    \n",
    "    return result_sort\n",
    "    \n",
    "###function to read data into pandas dataframe and remove NEI\n",
    "def read_tsv(file):\n",
    "    df_data = pd.read_json(file, lines=True)\n",
    "    df_data = df_data[df_data.label != 'NOT ENOUGH INFO']\n",
    "    df_data.loc[df_data.label == \"SUPPORTS\", \"label\"] = 1\n",
    "    df_data.loc[df_data.label == \"REFUTES\", \"label\"] = 2\n",
    "    return df_data\n",
    "    \n",
    "train_set = read_tsv('train.jsonl')\n",
    "train_df = format_examples(train_set)\n",
    "train_df = train_df.set_index('id')\n",
    "train_df.to_csv('train.tsv', sep=\"\\t\")\n",
    "\n",
    "dev_set = read_tsv('dev.jsonl')\n",
    "dev_df = format_examples(dev_set)\n",
    "dev_df = dev_df.set_index('id')\n",
    "dev_df.to_csv('dev.tsv', sep=\"\\t\")\n",
    "\n",
    "test_set = read_tsv('test.jsonl')\n",
    "test_df = format_examples(test_set)\n",
    "test_df = test_df.set_index('id')\n",
    "test_df.to_csv('test.tsv', sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
